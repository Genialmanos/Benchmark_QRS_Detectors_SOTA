{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066dc0a4-9330-4bef-b5aa-362a3e7a2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "#from utils import print_signal_qrs, print_signal, calcul_f1, perf\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from scipy.signal import resample\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7815b",
   "metadata": {},
   "source": [
    "# Le preprocessing dans l'article est un peu bizarre alors j'ai juste demandé à gpt de me faire un truc à peu près"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9409a39-84b1-4321-8cfb-a5de85a2e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(signal, fs):\n",
    "    clean_baseline = baseline_wander_removal(signal)\n",
    "    normalization = normalize_signal(clean_baseline)\n",
    "    return normalization\n",
    "\n",
    "def baseline_wander_removal(ecg_signal, window_size=4, sampling_rate=360, subsample_rate=200):\n",
    "    # Convert window size to number of samples\n",
    "    window_samples = window_size * sampling_rate\n",
    "    \n",
    "    # Initialize an empty array to store the corrected signal\n",
    "    corrected_signal = np.zeros_like(ecg_signal)\n",
    "    \n",
    "    # Process the signal in windows\n",
    "    for start in range(0, len(ecg_signal), window_samples):\n",
    "        end = min(start + window_samples, len(ecg_signal))\n",
    "        segment = ecg_signal[start:end]\n",
    "        \n",
    "        # Resample segment to reduce computational load\n",
    "        resampled_segment = resample(segment, subsample_rate)\n",
    "        \n",
    "        # Perform LOESS regression\n",
    "        x = np.linspace(0, len(resampled_segment) - 1, len(resampled_segment))\n",
    "        spline = UnivariateSpline(x, resampled_segment, s=len(resampled_segment))\n",
    "        baseline = spline(x)\n",
    "        \n",
    "        # Upsample the baseline back to the original sampling rate\n",
    "        baseline_full = resample(baseline, len(segment))\n",
    "        \n",
    "        # Subtract the baseline from the original segment\n",
    "        corrected_signal[start:end] = segment - baseline_full\n",
    "    \n",
    "    return corrected_signal\n",
    "\n",
    "def normalize_signal(ecg_signal):\n",
    "    mean_val = np.mean(ecg_signal)\n",
    "    std_val = np.std(ecg_signal)\n",
    "    \n",
    "    # Subtract mean and divide by standard deviation\n",
    "    normalized_signal = (ecg_signal - mean_val) / std_val\n",
    "    \n",
    "    return normalized_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87dca446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(ecg_signal, qrs_positions, fs, num_negative_samples=3):\n",
    "    points_before = int(100 * fs / 1000)\n",
    "    points_after = int(300 * fs / 1000)\n",
    "    total_points = points_before + points_after + 1\n",
    "\n",
    "    data_windows = []\n",
    "    labels = []\n",
    "    \n",
    "    tolerance = int(40 * fs / 1000)\n",
    "    \n",
    "    for qrs in qrs_positions:\n",
    "        start = qrs - points_before\n",
    "        end = qrs + points_after + 1\n",
    "        if start >= 0 and end <= len(ecg_signal):\n",
    "            window = ecg_signal[start:end]\n",
    "            if len(window) != total_points:\n",
    "                print(f\"Taille incorrecte: {len(window)} au lieu de {total_points}, start={start}, end={end}\")\n",
    "                continue\n",
    "            data_windows.append(window)\n",
    "            labels.append(1)\n",
    "    \n",
    "    num_qrs_positions = len(qrs_positions)\n",
    "    signal_length = len(ecg_signal)\n",
    "    negative_count = 0\n",
    "    \n",
    "    \n",
    "    data_windows_array = np.array([np.array(window) for window in data_windows if len(window) == total_points])\n",
    "    \n",
    "    return data_windows_array, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "368514cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53037115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2176</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">217,700</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m143\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │           \u001b[38;5;34m6,208\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2176\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m217,700\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,137</span> (875.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,137\u001b[0m (875.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,137</span> (875.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m224,137\u001b[0m (875.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer le modèle\n",
    "input_shape = (145, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63398151-e5b9-4ae1-8b20-dd4bd150cd3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "104\n",
      "107\n",
      "113\n",
      "116\n",
      "121\n",
      "201\n",
      "207\n",
      "209\n",
      "212\n",
      "215\n",
      "219\n",
      "228\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "\n",
    "for file in ['101', '104', '107', '113', '116', '121', '201', '207', '209', '212', '215', '219', '228', '233']:\n",
    "    print(file)\n",
    "    df = pd.read_csv(f'data_csv/mit_bih_Arrhythmia/{file}.csv') #207\n",
    "    ecg_signal = None\n",
    "    if file == \"104\":\n",
    "        ecg_signal = np.array(df[\"V2\"], dtype=np.float32)#[:10000]\n",
    "    else:\n",
    "        ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)#[:10000]\n",
    "    fs = 360\n",
    "    QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "    labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "    cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "    \n",
    "    X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    X_train_all.extend(X_train)\n",
    "    X_test_all.extend(X_test)\n",
    "    y_train_all.extend(y_train)\n",
    "    y_test_all.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74cb2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0183\n",
      "Epoch 2/5\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9915e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2030e-07\n",
      "Epoch 4/5\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8355e-08\n",
      "Epoch 5/5\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1995e-08\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "input_shape = (145, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "history = model.fit(np.array(X_train_all), np.array(y_train_all), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f9ca5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_windows(ecg_signal, qrs_positions, fs, num_negative_samples=3):\n",
    "    # Recalculer les points avant et après le QRS en fonction de la fréquence\n",
    "    points_before = int(100 * fs / 1000)\n",
    "    points_after = int(300 * fs / 1000)\n",
    "    total_points = points_before + points_after + 1\n",
    "    \n",
    "    # Affiche un ajustement basé sur la nouvelle fréquence si différent de 101 pour fs=250\n",
    "    if fs == 250 and total_points != 101:\n",
    "        print(f\"Erreur: le nombre total de points par fenêtre est {total_points}, mais 101 sont attendus pour fs=250.\")\n",
    "        points_after += 101 - total_points\n",
    "        total_points = points_before + points_after + 1  # Recalcule total_points si nécessaire\n",
    "\n",
    "    data_windows = []\n",
    "    labels = []\n",
    "    \n",
    "    tolerance = int(40 * fs / 1000)\n",
    "    \n",
    "    # Fenêtres positives\n",
    "    for qrs in qrs_positions:\n",
    "        start = qrs - points_before\n",
    "        end = qrs + points_after + 1\n",
    "        if start >= 0 and end <= len(ecg_signal):\n",
    "            window = ecg_signal[start:end]\n",
    "            if len(window) != total_points:\n",
    "                print(f\"Taille incorrecte: {len(window)} au lieu de {total_points}, start={start}, end={end}\")\n",
    "                continue\n",
    "            data_windows.append(window)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Fenêtres négatives\n",
    "    num_qrs_positions = len(qrs_positions)\n",
    "    signal_length = len(ecg_signal)\n",
    "    negative_count = 0\n",
    "    \n",
    "    while negative_count < num_qrs_positions * num_negative_samples:\n",
    "        start = np.random.randint(0, signal_length - total_points)\n",
    "        end = start + total_points\n",
    "        \n",
    "        # Vérifiez si la fenêtre chevauche un complexe QRS\n",
    "        is_positive = any(abs(start + points_before - qrs) <= tolerance for qrs in qrs_positions)\n",
    "        if not is_positive:\n",
    "            window = ecg_signal[start:end]\n",
    "            if len(window) != total_points:\n",
    "                print(f\"Taille incorrecte (négative): {len(window)} au lieu de {total_points}, start={start}, end={end}\")\n",
    "                continue\n",
    "            data_windows.append(window)\n",
    "            labels.append(0)\n",
    "            negative_count += 1\n",
    "    \n",
    "    # Convertir data_windows en un numpy array de manière sécurisée\n",
    "    data_windows_array = np.array([np.array(window) for window in data_windows if len(window) == total_points])\n",
    "    labels_array = np.array(labels)\n",
    "    \n",
    "    # Vérifiez si les dimensions sont correctes\n",
    "    if data_windows_array.ndim == 1 or data_windows_array.shape[1] != total_points:\n",
    "        print(\"Erreur dans la transformation finale des fenêtres de données.\")\n",
    "        print(f\"Forme finale attendue: (?, {total_points}), obtenue: {data_windows_array.shape}\")\n",
    "    \n",
    "    return data_windows_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cb4a7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "\n",
    "for file in range(103, 151):\n",
    "    print(file)\n",
    "    try:\n",
    "        df = pd.read_csv(f'data_csv/european/e0{file}.csv') #207\n",
    "    except:\n",
    "        continue\n",
    "    ecg_signal = None\n",
    "    \n",
    "    if \"MLIII\" in df.columns:\n",
    "        ecg_signal = np.array(df[\"MLIII\"], dtype=np.float32)#[:10000]\n",
    "    else:\n",
    "        continue\n",
    "    fs = 250\n",
    "    QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "    labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "    cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "    \n",
    "    X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    X_train_all.extend(X_train)\n",
    "    X_test_all.extend(X_test)\n",
    "    y_train_all.extend(y_train)\n",
    "    y_test_all.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c9f16672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0594\n",
      "Epoch 2/5\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0359\n",
      "Epoch 3/5\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0326\n",
      "Epoch 4/5\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0319\n",
      "Epoch 5/5\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0303\n"
     ]
    }
   ],
   "source": [
    "input_shape = (101, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "history = model.fit(np.array(X_train_all), np.array(y_train_all), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e132339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN_european.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b46118c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C n'a pas de nom.\n",
      " Le num‚ro de s‚rie du volume est 1AC4-BB4B\n",
      "\n",
      " R‚pertoire de C:\\Users\\Dieu\\Octo\\Benchmark_QRS_Detectors_SOTA\\benchmark_qrs_detectors\\output\\perf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier introuvable\n"
     ]
    }
   ],
   "source": [
    "ls \"../benchmark_qrs_detectors/output/perf/arr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "55fcfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(ecg_signal, qrs_positions, fs, num_negative_samples=3):\n",
    "    # Recalculer les points avant et après le QRS en fonction de la fréquence\n",
    "    points_before = int(100 * fs / 1000)\n",
    "    points_after = int(300 * fs / 1000)\n",
    "    total_points = points_before + points_after + 1\n",
    "    \n",
    "    # Affiche un ajustement basé sur la nouvelle fréquence si différent de 101 pour fs=250\n",
    "    if total_points != 51:\n",
    "        print(f\"Erreur: le nombre total de points par fenêtre est {total_points}, mais 101 sont attendus pour fs=250.\")\n",
    "        points_after += 51 - total_points\n",
    "        total_points = points_before + points_after + 1  # Recalcule total_points si nécessaire\n",
    "\n",
    "    data_windows = []\n",
    "    labels = []\n",
    "    \n",
    "    tolerance = int(40 * fs / 1000)\n",
    "    \n",
    "    # Fenêtres positives\n",
    "    for qrs in qrs_positions:\n",
    "        start = qrs - points_before\n",
    "        end = qrs + points_after + 1\n",
    "        if start >= 0 and end <= len(ecg_signal):\n",
    "            window = ecg_signal[start:end]\n",
    "            if len(window) != total_points:\n",
    "                print(f\"Taille incorrecte: {len(window)} au lieu de {total_points}, start={start}, end={end}\")\n",
    "                continue\n",
    "            data_windows.append(window)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Fenêtres négatives\n",
    "    num_qrs_positions = len(qrs_positions)\n",
    "    signal_length = len(ecg_signal)\n",
    "    negative_count = 0\n",
    "    \n",
    "    while negative_count < num_qrs_positions * num_negative_samples:\n",
    "        start = np.random.randint(0, signal_length - total_points)\n",
    "        end = start + total_points\n",
    "        \n",
    "        # Vérifiez si la fenêtre chevauche un complexe QRS\n",
    "        is_positive = any(abs(start + points_before - qrs) <= tolerance for qrs in qrs_positions)\n",
    "        if not is_positive:\n",
    "            window = ecg_signal[start:end]\n",
    "            if len(window) != total_points:\n",
    "                print(f\"Taille incorrecte (négative): {len(window)} au lieu de {total_points}, start={start}, end={end}\")\n",
    "                continue\n",
    "            data_windows.append(window)\n",
    "            labels.append(0)\n",
    "            negative_count += 1\n",
    "    \n",
    "    # Convertir data_windows en un numpy array de manière sécurisée\n",
    "    data_windows_array = np.array([np.array(window) for window in data_windows if len(window) == total_points])\n",
    "    labels_array = np.array(labels)\n",
    "    \n",
    "    # Vérifiez si les dimensions sont correctes\n",
    "    if data_windows_array.ndim == 1 or data_windows_array.shape[1] != total_points:\n",
    "        print(\"Erreur dans la transformation finale des fenêtres de données.\")\n",
    "        print(f\"Forme finale attendue: (?, {total_points}), obtenue: {data_windows_array.shape}\")\n",
    "    \n",
    "    return data_windows_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3c5f7231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "\n",
    "for file in range(800, 845):\n",
    "    print(file)\n",
    "    df = None\n",
    "    try:\n",
    "        df = pd.read_csv(f'data_csv/mit_bih_supraventricular/{file}.csv') #207\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    ecg_signal = np.array(df[\"ECG1\"], dtype=np.float32)#[:10000]\n",
    "\n",
    "    fs = 128\n",
    "    QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "    labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "    cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "    \n",
    "    X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    X_train_all.extend(X_train)\n",
    "    X_test_all.extend(X_test)\n",
    "    y_train_all.extend(y_train)\n",
    "    y_test_all.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ad799370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0525\n",
      "Epoch 2/5\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0179\n",
      "Epoch 3/5\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0149\n",
      "Epoch 4/5\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0137\n",
      "Epoch 5/5\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0126\n"
     ]
    }
   ],
   "source": [
    "input_shape = (51, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "history = model.fit(np.array(X_train_all), np.array(y_train_all), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c0eea18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN_supra.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "18c3bc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbofbeats    2417.408163\n",
       "FP             24.448980\n",
       "FN             11.693878\n",
       "F              36.142857\n",
       "F(%)            1.377755\n",
       "P+(%)          99.102041\n",
       "Se(%)          99.565918\n",
       "F1(%)          99.321837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../benchmark_qrs_detectors/output/perf/CNN_mit-bih-supraventricular-arrhythmia_100.csv', index_col=0)\n",
    "# Convertir l'index en entier pour pouvoir le comparer\n",
    "df.index = df.index.astype(int)\n",
    "\n",
    "# Filtrer les lignes où l'index est supérieur à 153\n",
    "filtered_df = df[df.index > 845]\n",
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d15d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab9027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "997c5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14149\n",
      "14134\n",
      "14046\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "\n",
    "for file in ['14149','14134','14046']:\n",
    "    print(file)\n",
    "    df = None\n",
    "    try:\n",
    "        df = pd.read_csv(f'data_csv/mit_bih_long_term/{file}.csv') #207\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    ecg_signal = np.array(df[\"ECG1\"], dtype=np.float32)#[:10000]\n",
    "\n",
    "    fs = 128\n",
    "    QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "    labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "    cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "    \n",
    "    X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    X_train_all.extend(X_train)\n",
    "    X_test_all.extend(X_test)\n",
    "    y_train_all.extend(y_train)\n",
    "    y_test_all.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3cd78128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m19368/19368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0134\n",
      "Epoch 2/5\n",
      "\u001b[1m19368/19368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0067\n",
      "Epoch 3/5\n",
      "\u001b[1m19368/19368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0063\n",
      "Epoch 4/5\n",
      "\u001b[1m19368/19368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0057\n",
      "Epoch 5/5\n",
      "\u001b[1m19368/19368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0060\n"
     ]
    }
   ],
   "source": [
    "input_shape = (51, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "history = model.fit(np.array(X_train_all), np.array(y_train_all), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "31eac1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN_long_term.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6c9b490b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../benchmark_qrs_detectors/output/perf/CNN_mit-bih-supraventricular-arrhythmia_100.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../benchmark_qrs_detectors/output/perf/CNN_mit-bih-supraventricular-arrhythmia_100.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Convertir l'index en entier pour pouvoir le comparer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../benchmark_qrs_detectors/output/perf/CNN_mit-bih-supraventricular-arrhythmia_100.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'../benchmark_qrs_detectors/output/perf/CNN_mit-bih-supraventricular-arrhythmia_100.csv', index_col=0)\n",
    "# Convertir l'index en entier pour pouvoir le comparer\n",
    "df.index = df.index.astype(int)\n",
    "\n",
    "# Filtrer les lignes où l'index est supérieur à 153\n",
    "filtered_df = df[df.index > 14149]\n",
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90820fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "919039dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbofbats    9270.868852\n",
       "FP           153.262295\n",
       "FN            51.918033\n",
       "F            205.180328\n",
       "F(%)           2.224918\n",
       "P+(%)         98.437213\n",
       "S(%)          99.429508\n",
       "F1(%)         98.910656\n",
       "dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../benchmark_qrs_detectors/output/perf/CNN_european-stt_100.csv', index_col=0)\n",
    "# Convertir l'index en entier pour pouvoir le comparer\n",
    "df.index = df.index.astype(int)\n",
    "\n",
    "# Filtrer les lignes où l'index est supérieur à 153\n",
    "filtered_df = df[df.index > 153]\n",
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bd744d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nbofbeats</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>F</th>\n",
       "      <th>F(%)</th>\n",
       "      <th>P+(%)</th>\n",
       "      <th>Se(%)</th>\n",
       "      <th>F1(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2273</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>99.78</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1865</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.97</td>\n",
       "      <td>99.04</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2187</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2.93</td>\n",
       "      <td>97.16</td>\n",
       "      <td>100.00</td>\n",
       "      <td>98.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2084</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>99.76</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2229</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>216</td>\n",
       "      <td>9.69</td>\n",
       "      <td>91.23</td>\n",
       "      <td>99.91</td>\n",
       "      <td>95.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2572</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>233</td>\n",
       "      <td>9.06</td>\n",
       "      <td>92.08</td>\n",
       "      <td>99.49</td>\n",
       "      <td>95.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2027</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.59</td>\n",
       "      <td>99.41</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2137</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "      <td>99.44</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1763</td>\n",
       "      <td>257</td>\n",
       "      <td>25</td>\n",
       "      <td>282</td>\n",
       "      <td>16.00</td>\n",
       "      <td>87.12</td>\n",
       "      <td>98.58</td>\n",
       "      <td>92.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.80</td>\n",
       "      <td>99.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2124</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>9.98</td>\n",
       "      <td>90.99</td>\n",
       "      <td>99.91</td>\n",
       "      <td>95.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2539</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>2.99</td>\n",
       "      <td>97.09</td>\n",
       "      <td>100.00</td>\n",
       "      <td>98.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1795</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2.06</td>\n",
       "      <td>98.03</td>\n",
       "      <td>99.94</td>\n",
       "      <td>98.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1879</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>99.52</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1953</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.31</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2412</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>1.49</td>\n",
       "      <td>99.38</td>\n",
       "      <td>99.13</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1535</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>99.61</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2278</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1.36</td>\n",
       "      <td>98.70</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1987</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1.16</td>\n",
       "      <td>98.86</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1863</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2.31</td>\n",
       "      <td>97.84</td>\n",
       "      <td>99.89</td>\n",
       "      <td>98.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1518</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>99.48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1619</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>99.69</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2601</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.54</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.88</td>\n",
       "      <td>99.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1963</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>99.19</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2136</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.80</td>\n",
       "      <td>99.26</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2980</td>\n",
       "      <td>101</td>\n",
       "      <td>40</td>\n",
       "      <td>141</td>\n",
       "      <td>4.73</td>\n",
       "      <td>96.68</td>\n",
       "      <td>98.66</td>\n",
       "      <td>97.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2656</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>99.81</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1860</td>\n",
       "      <td>627</td>\n",
       "      <td>5</td>\n",
       "      <td>632</td>\n",
       "      <td>33.98</td>\n",
       "      <td>74.74</td>\n",
       "      <td>99.73</td>\n",
       "      <td>85.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2955</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>98.46</td>\n",
       "      <td>99.39</td>\n",
       "      <td>98.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>3005</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1.96</td>\n",
       "      <td>98.07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2650</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>98.95</td>\n",
       "      <td>99.81</td>\n",
       "      <td>99.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2748</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>2.84</td>\n",
       "      <td>97.27</td>\n",
       "      <td>99.96</td>\n",
       "      <td>98.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3251</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>99.72</td>\n",
       "      <td>99.97</td>\n",
       "      <td>99.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2262</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>99.91</td>\n",
       "      <td>99.82</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3363</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>99.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2208</td>\n",
       "      <td>163</td>\n",
       "      <td>15</td>\n",
       "      <td>178</td>\n",
       "      <td>8.06</td>\n",
       "      <td>93.08</td>\n",
       "      <td>99.32</td>\n",
       "      <td>96.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2154</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>9.47</td>\n",
       "      <td>91.35</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2048</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2427</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.66</td>\n",
       "      <td>99.39</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2483</td>\n",
       "      <td>495</td>\n",
       "      <td>7</td>\n",
       "      <td>502</td>\n",
       "      <td>20.22</td>\n",
       "      <td>83.34</td>\n",
       "      <td>99.72</td>\n",
       "      <td>90.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2605</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>99.73</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2053</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2.97</td>\n",
       "      <td>97.25</td>\n",
       "      <td>99.85</td>\n",
       "      <td>98.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2256</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.20</td>\n",
       "      <td>98.82</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1571</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.15</td>\n",
       "      <td>98.87</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1780</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.13</td>\n",
       "      <td>97.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>98.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3079</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>99.84</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2753</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>99.71</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nbofbeats   FP  FN    F   F(%)   P+(%)   Se(%)  F1(%)\n",
       "100       2273    5   1    6   0.26   99.78   99.96  99.87\n",
       "101       1865   18   0   18   0.97   99.04  100.00  99.52\n",
       "102       2187   64   0   64   2.93   97.16  100.00  98.56\n",
       "103       2084    5   0    5   0.24   99.76  100.00  99.88\n",
       "104       2229  214   2  216   9.69   91.23   99.91  95.37\n",
       "105       2572  220  13  233   9.06   92.08   99.49  95.65\n",
       "106       2027   12   0   12   0.59   99.41  100.00  99.70\n",
       "107       2137   12   1   13   0.61   99.44   99.95  99.70\n",
       "108       1763  257  25  282  16.00   87.12   98.58  92.50\n",
       "109       2532    1   5    6   0.24   99.96   99.80  99.88\n",
       "111       2124  210   2  212   9.98   90.99   99.91  95.24\n",
       "112       2539   76   0   76   2.99   97.09  100.00  98.53\n",
       "113       1795   36   1   37   2.06   98.03   99.94  98.98\n",
       "114       1879    9   0    9   0.48   99.52  100.00  99.76\n",
       "115       1953    5   1    6   0.31   99.74   99.95  99.85\n",
       "116       2412   15  21   36   1.49   99.38   99.13  99.25\n",
       "117       1535    6   1    7   0.46   99.61   99.93  99.77\n",
       "118       2278   30   1   31   1.36   98.70   99.96  99.32\n",
       "119       1987   23   0   23   1.16   98.86  100.00  99.42\n",
       "121       1863   41   2   43   2.31   97.84   99.89  98.86\n",
       "122       2476    0   1    1   0.04  100.00   99.96  99.98\n",
       "123       1518    8   0    8   0.53   99.48  100.00  99.74\n",
       "124       1619    5   0    5   0.31   99.69  100.00  99.85\n",
       "200       2601   11   3   14   0.54   99.58   99.88  99.73\n",
       "201       1963   16   0   16   0.82   99.19  100.00  99.59\n",
       "202       2136   16   1   17   0.80   99.26   99.95  99.60\n",
       "203       2980  101  40  141   4.73   96.68   98.66  97.66\n",
       "205       2656    5   1    6   0.23   99.81   99.96  99.89\n",
       "207       1860  627   5  632  33.98   74.74   99.73  85.44\n",
       "208       2955   46  18   64   2.17   98.46   99.39  98.92\n",
       "209       3005   59   0   59   1.96   98.07  100.00  99.03\n",
       "210       2650   28   5   33   1.25   98.95   99.81  99.38\n",
       "212       2748   77   1   78   2.84   97.27   99.96  98.60\n",
       "213       3251    9   1   10   0.31   99.72   99.97  99.85\n",
       "214       2262    2   4    6   0.27   99.91   99.82  99.87\n",
       "215       3363    3   0    3   0.09   99.91  100.00  99.96\n",
       "217       2208  163  15  178   8.06   93.08   99.32  96.10\n",
       "219       2154  204   0  204   9.47   91.35  100.00  95.48\n",
       "220       2048    2   2    4   0.20   99.90   99.90  99.90\n",
       "221       2427   15   1   16   0.66   99.39   99.96  99.67\n",
       "222       2483  495   7  502  20.22   83.34   99.72  90.80\n",
       "223       2605    7   2    9   0.35   99.73   99.92  99.83\n",
       "228       2053   58   3   61   2.97   97.25   99.85  98.53\n",
       "230       2256   27   0   27   1.20   98.82  100.00  99.41\n",
       "231       1571   18   0   18   1.15   98.87  100.00  99.43\n",
       "232       1780   38   0   38   2.13   97.91  100.00  98.94\n",
       "233       3079    5   3    8   0.26   99.84   99.90  99.87\n",
       "234       2753    8   0    8   0.29   99.71  100.00  99.85"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e9fb08ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbofbeats    2263.764706\n",
       "FP             56.676471\n",
       "FN              4.411765\n",
       "F              61.088235\n",
       "F(%)            2.691176\n",
       "P+(%)          97.707941\n",
       "Se(%)          99.817647\n",
       "F1(%)          98.715588\n",
       "dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../benchmark_qrs_detectors/output/perf/arr.csv\", index_col=0)\n",
    "# Convertir l'index en entier pour pouvoir le comparer\n",
    "#df.index = df.index.astype(int)\n",
    "excluded_indices = [101, 104, 107, 113, 116, 121, 201, 207, 209, 212, 215, 219, 228, 233]\n",
    "filtered_df = df[~df.index.isin(excluded_indices)]\n",
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1111068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "06\n",
      "12\n",
      "18\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "\n",
    "for file in ['00', '06', '12', '18', '24']:\n",
    "    print(file)\n",
    "    df = pd.read_csv(f'data_csv/mit_bih_noise_stress/118e{file}.csv') #207\n",
    "    ecg_signal = None\n",
    "    ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)#[:10000]\n",
    "    fs = 360\n",
    "    QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "    labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "    cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "    \n",
    "    X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    X_train_all.extend(X_train)\n",
    "    X_test_all.extend(X_test)\n",
    "    y_train_all.extend(y_train)\n",
    "    y_test_all.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "797ba72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0735\n",
      "Epoch 2/5\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0299\n",
      "Epoch 3/5\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0262\n",
      "Epoch 4/5\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0209\n",
      "Epoch 5/5\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "input_shape = (145, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "history = model.fit(np.array(X_train_all), np.array(y_train_all), epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e1b7968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN_full_noisy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1b06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c24217",
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_bih_noise_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f9061672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_csv/mit_bih_noise_stress/118e06.csv') #207\n",
    "ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)#[:10000]\n",
    "fs = 360\n",
    "QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "cleaned_ecg = preprocessing(ecg_signal, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc1770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_csv/mit_bih_Arrhythmia/100.csv') #207\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e8ccffc-2232-447a-be9d-675f1851ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0684 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 2/3\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0236 - val_accuracy: 0.9892 - val_loss: 0.0157\n",
      "Epoch 3/3\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0285 - val_accuracy: 1.0000 - val_loss: 1.1452e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_csv/mit_bih_noise_stress/118e24.csv') #207\n",
    "ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)#[:10000]\n",
    "fs = 360\n",
    "QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "\n",
    "X, y = create_windows(cleaned_ecg, QRS, fs)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "input_shape = (145, 1)  # 145 points par fenêtre, 1 canal\n",
    "model = create_model(input_shape)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=16, validation_data=(X_test, y_test))\n",
    "model.save(\"../benchmark_qrs_detectors/model_CNN_noise_24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af17ef63-8e64-4df5-b587-ee8588d2dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal de longueur: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_signal(cleaned_ecg[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59c56fe-22bb-4c3f-b3bf-8bfec2f3541a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1873"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d1baaa5-26ba-484e-9a92-95de913f89d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dbcbd41-e7b6-4a74-aa01-d5be1132c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "joblib.dump(model, open(\"../benchmark_qrs_detectors/model_CNN\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ab592ee-f9b5-4cb3-bacb-cb1f64b69ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../benchmark_qrs_detectors/model_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c39766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows_sig(signal, fs):\n",
    "    # Points avant et après basés sur la fréquence d'échantillonnage\n",
    "    points_before = int(100 * fs / 1000)\n",
    "    points_after = int(300 * fs / 1000)\n",
    "    total_points = points_before + points_after + 1\n",
    "    \n",
    "    if total_points != 145:\n",
    "        raise ValueError(f\"La fenêtre calculée a {total_points} points, mais 145 sont attendus.\")\n",
    "    \n",
    "    # Extraire les fenêtres pour chaque point dans cleaned_ecg\n",
    "    windows = []\n",
    "    for i in range(len(signal)):\n",
    "        start = i - points_before\n",
    "        end = i + points_after + 1\n",
    "        if start >= 0 and end <= len(signal):\n",
    "            window = signal[start:end]\n",
    "            if len(window) == 145:\n",
    "                windows.append(window)\n",
    "    \n",
    "    return np.array(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3dc7f665-261b-4874-bfaa-71015b02eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20308/20308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_csv/mit_bih_Arrhythmia/207.csv') #207\n",
    "ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)#[:10000]\n",
    "fs = 360\n",
    "QRS = df[\"labels\"].dropna().astype(int).tolist()\n",
    "labels = np.zeros(len(ecg_signal))\n",
    "\n",
    "cleaned_ecg = preprocessing(ecg_signal, fs)\n",
    "X = extract_windows_sig(cleaned_ecg, fs)\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17b058bd-8f57-4103-b49e-459eef3fcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predos = pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f700805c-f3e9-40ec-8988-9226dc6ff0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup(peaks, thr):\n",
    "    diff = peaks[1:]-peaks[:-1]\n",
    "    gps = np.concatenate([[0], np.cumsum(diff>=thr)])\n",
    "    temp = [peaks[gps==i] for i in range(gps[-1]+1)]\n",
    "    max_sublist = []\n",
    "    return [np.mean(sublist).astype(int) for sublist in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "830f5e49-3c44-4b20-98d4-7cb8f1c689bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_frame = [a+36 for a in range(len(predos)) if predos[a] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32fe99fb-b9e4-46ea-8e6e-b7dbb88daa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = regroup(np.array(pred_frame), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1a93f7f-d36d-4252-81f2-b9ee7c79e367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260,\n",
       " 332,\n",
       " 324,\n",
       " 0.8732612055641422,\n",
       " [array([9]),\n",
       "  array([1429]),\n",
       "  array([2869]),\n",
       "  array([4311]),\n",
       "  array([11659]),\n",
       "  array([13868]),\n",
       "  array([13965, 13967, 14001]),\n",
       "  array([14750]),\n",
       "  array([15094]),\n",
       "  array([15586]),\n",
       "  array([15726, 15759, 15775]),\n",
       "  array([16083, 16112, 16138, 16157]),\n",
       "  array([16214]),\n",
       "  array([16324]),\n",
       "  array([16441]),\n",
       "  array([16554]),\n",
       "  array([16665]),\n",
       "  array([17191, 17218, 17228]),\n",
       "  array([17304]),\n",
       "  array([17509, 17511, 17546]),\n",
       "  array([17670]),\n",
       "  array([17798]),\n",
       "  array([17923]),\n",
       "  array([18080]),\n",
       "  array([18350]),\n",
       "  array([18396]),\n",
       "  array([19715]),\n",
       "  array([19760]),\n",
       "  array([20255]),\n",
       "  array([21045]),\n",
       "  array([21092]),\n",
       "  array([21731]),\n",
       "  array([21827]),\n",
       "  array([22262]),\n",
       "  array([22774]),\n",
       "  array([23313]),\n",
       "  array([25627]),\n",
       "  array([26396, 26399, 26430]),\n",
       "  array([27256]),\n",
       "  array([28035, 28039, 28072]),\n",
       "  array([28179, 28182, 28212]),\n",
       "  array([29585]),\n",
       "  array([30235]),\n",
       "  array([46901, 46903, 46934]),\n",
       "  array([47591, 47596, 47630]),\n",
       "  array([48133]),\n",
       "  array([48244, 48247, 48279]),\n",
       "  array([73443]),\n",
       "  array([77767, 77794, 77806]),\n",
       "  array([83525, 83557, 83570]),\n",
       "  array([84963]),\n",
       "  array([86414, 86425, 86454]),\n",
       "  array([86540]),\n",
       "  array([87172]),\n",
       "  array([87214]),\n",
       "  array([87486, 87521, 87529]),\n",
       "  array([88086, 88121, 88125]),\n",
       "  array([88716]),\n",
       "  array([88788]),\n",
       "  array([89242]),\n",
       "  array([89320]),\n",
       "  array([89372]),\n",
       "  array([89627]),\n",
       "  array([90002]),\n",
       "  array([90131]),\n",
       "  array([90308]),\n",
       "  array([90848, 90853, 90885]),\n",
       "  array([91009]),\n",
       "  array([91121]),\n",
       "  array([91238]),\n",
       "  array([92465]),\n",
       "  array([92569]),\n",
       "  array([92683]),\n",
       "  array([93291, 93297, 93329]),\n",
       "  array([94122]),\n",
       "  array([94220]),\n",
       "  array([95031]),\n",
       "  array([96162, 96163, 96194]),\n",
       "  array([97008, 97019, 97051]),\n",
       "  array([97220]),\n",
       "  array([97336]),\n",
       "  array([97450]),\n",
       "  array([97567]),\n",
       "  array([97693]),\n",
       "  array([97729]),\n",
       "  array([98446]),\n",
       "  array([98591]),\n",
       "  array([98896]),\n",
       "  array([99000]),\n",
       "  array([99100]),\n",
       "  array([99273, 99277, 99311]),\n",
       "  array([99416]),\n",
       "  array([100767, 100801, 100804, 100828]),\n",
       "  array([101126]),\n",
       "  array([101185]),\n",
       "  array([101933]),\n",
       "  array([102247]),\n",
       "  array([103849]),\n",
       "  array([104150]),\n",
       "  array([104569, 104596, 104598]),\n",
       "  array([104694]),\n",
       "  array([105129]),\n",
       "  array([105294]),\n",
       "  array([106438]),\n",
       "  array([106488]),\n",
       "  array([106565]),\n",
       "  array([108421]),\n",
       "  array([108704]),\n",
       "  array([109436]),\n",
       "  array([110840]),\n",
       "  array([111757]),\n",
       "  array([115205]),\n",
       "  array([115469]),\n",
       "  array([115742]),\n",
       "  array([116222]),\n",
       "  array([116418]),\n",
       "  array([116490]),\n",
       "  array([116617, 116646, 116647]),\n",
       "  array([118277]),\n",
       "  array([118513]),\n",
       "  array([118832]),\n",
       "  array([119000]),\n",
       "  array([119773]),\n",
       "  array([120066]),\n",
       "  array([120246]),\n",
       "  array([120564]),\n",
       "  array([120774]),\n",
       "  array([121788]),\n",
       "  array([122068]),\n",
       "  array([123652, 123686, 123717]),\n",
       "  array([124554]),\n",
       "  array([126717]),\n",
       "  array([128119]),\n",
       "  array([128169]),\n",
       "  array([132445, 132448, 132474]),\n",
       "  array([138709]),\n",
       "  array([145366]),\n",
       "  array([149757]),\n",
       "  array([150744, 150774, 150777]),\n",
       "  array([150920]),\n",
       "  array([151197]),\n",
       "  array([151365, 151367, 151399]),\n",
       "  array([151602]),\n",
       "  array([152645]),\n",
       "  array([159775]),\n",
       "  array([159946]),\n",
       "  array([161027]),\n",
       "  array([161076]),\n",
       "  array([161283]),\n",
       "  array([170465]),\n",
       "  array([171017]),\n",
       "  array([171300]),\n",
       "  array([171350]),\n",
       "  array([172103]),\n",
       "  array([173584]),\n",
       "  array([175683]),\n",
       "  array([176539]),\n",
       "  array([177119]),\n",
       "  array([177659]),\n",
       "  array([178014]),\n",
       "  array([178551]),\n",
       "  array([179121]),\n",
       "  array([179200, 179228, 179228]),\n",
       "  array([186227, 186253, 186255]),\n",
       "  array([186614]),\n",
       "  array([186859]),\n",
       "  array([190007]),\n",
       "  array([201548]),\n",
       "  array([241917]),\n",
       "  array([243359]),\n",
       "  array([266397]),\n",
       "  array([269277]),\n",
       "  array([272123]),\n",
       "  array([292282]),\n",
       "  array([298077]),\n",
       "  array([300922]),\n",
       "  array([331195]),\n",
       "  array([332602]),\n",
       "  array([332651]),\n",
       "  array([383326, 383354, 383355]),\n",
       "  array([401749]),\n",
       "  array([444917, 444919, 444952]),\n",
       "  array([452164]),\n",
       "  array([475203]),\n",
       "  array([514081]),\n",
       "  array([534205, 534207, 534236]),\n",
       "  array([547205]),\n",
       "  array([551437]),\n",
       "  array([551536]),\n",
       "  array([551800]),\n",
       "  array([554068]),\n",
       "  array([554682]),\n",
       "  array([554740]),\n",
       "  array([555649]),\n",
       "  array([555763]),\n",
       "  array([555804, 555806, 555828]),\n",
       "  array([555906]),\n",
       "  array([555948]),\n",
       "  array([556590, 556597, 556626]),\n",
       "  array([557584]),\n",
       "  array([557694]),\n",
       "  array([557807]),\n",
       "  array([558766]),\n",
       "  array([559435]),\n",
       "  array([559484, 559494, 559525]),\n",
       "  array([559578, 559579, 559606]),\n",
       "  array([559751]),\n",
       "  array([560046]),\n",
       "  array([560164]),\n",
       "  array([560437, 560440, 560471]),\n",
       "  array([560619]),\n",
       "  array([561017]),\n",
       "  array([561545]),\n",
       "  array([561673]),\n",
       "  array([561777]),\n",
       "  array([561880]),\n",
       "  array([561947, 561951, 561985]),\n",
       "  array([562052, 562059, 562090]),\n",
       "  array([562257, 562263, 562295]),\n",
       "  array([562401]),\n",
       "  array([562768, 562780, 562808]),\n",
       "  array([563210]),\n",
       "  array([563529]),\n",
       "  array([563629]),\n",
       "  array([563736]),\n",
       "  array([563843]),\n",
       "  array([563953]),\n",
       "  array([564260]),\n",
       "  array([564808, 564810, 564844]),\n",
       "  array([565525]),\n",
       "  array([566459]),\n",
       "  array([566559]),\n",
       "  array([566657]),\n",
       "  array([566760]),\n",
       "  array([567046]),\n",
       "  array([567941, 567969, 567979]),\n",
       "  array([568766, 568767, 568797]),\n",
       "  array([568927]),\n",
       "  array([570212, 570213, 570241]),\n",
       "  array([570287, 570312, 570346]),\n",
       "  array([571950]),\n",
       "  array([572246]),\n",
       "  array([572287]),\n",
       "  array([573310, 573316, 573347]),\n",
       "  array([573399, 573404, 573438]),\n",
       "  array([573534]),\n",
       "  array([573851]),\n",
       "  array([573955, 573990, 573992]),\n",
       "  array([574060, 574093, 574109]),\n",
       "  array([574314]),\n",
       "  array([574433]),\n",
       "  array([574957, 574962, 574995]),\n",
       "  array([575557]),\n",
       "  array([575662]),\n",
       "  array([575828, 575830, 575862]),\n",
       "  array([576027]),\n",
       "  array([576309]),\n",
       "  array([576389, 576405, 576433]),\n",
       "  array([576617, 576647, 576672]),\n",
       "  array([576731]),\n",
       "  array([576835]),\n",
       "  array([576969]),\n",
       "  array([577092]),\n",
       "  array([577173]),\n",
       "  array([577272]),\n",
       "  array([577374]),\n",
       "  array([577481]),\n",
       "  array([577718]),\n",
       "  array([577872]),\n",
       "  array([577998]),\n",
       "  array([578055]),\n",
       "  array([578231]),\n",
       "  array([578332]),\n",
       "  array([578435, 578441, 578472]),\n",
       "  array([578521]),\n",
       "  array([578626, 578660, 578661]),\n",
       "  array([578735]),\n",
       "  array([579829]),\n",
       "  array([580175]),\n",
       "  array([580276]),\n",
       "  array([580380]),\n",
       "  array([580482]),\n",
       "  array([580596]),\n",
       "  array([580763]),\n",
       "  array([581411]),\n",
       "  array([581598]),\n",
       "  array([581905]),\n",
       "  array([582736]),\n",
       "  array([582775]),\n",
       "  array([582822]),\n",
       "  array([584688]),\n",
       "  array([584784]),\n",
       "  array([584842]),\n",
       "  array([584878]),\n",
       "  array([585098]),\n",
       "  array([585194]),\n",
       "  array([585587]),\n",
       "  array([585690]),\n",
       "  array([586072]),\n",
       "  array([586675]),\n",
       "  array([586729, 586731, 586765]),\n",
       "  array([587071]),\n",
       "  array([587391]),\n",
       "  array([587508]),\n",
       "  array([587635]),\n",
       "  array([588809]),\n",
       "  array([589087]),\n",
       "  array([589203]),\n",
       "  array([589926]),\n",
       "  array([590149]),\n",
       "  array([592274, 592308, 592309]),\n",
       "  array([616118]),\n",
       "  array([622931]),\n",
       "  array([623026]),\n",
       "  array([623487]),\n",
       "  array([629386]),\n",
       "  array([629482]),\n",
       "  array([631361]),\n",
       "  array([634997]),\n",
       "  array([637873]),\n",
       "  array([645154]),\n",
       "  array([646603])])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(QRS, final_pred, 36, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
