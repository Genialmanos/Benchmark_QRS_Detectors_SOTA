{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fbab95-a701-434a-b2ca-6e1f9c4dab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import csv\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt\n",
    "#from PyEMD import EMD\n",
    "import emd\n",
    "import time\n",
    "import pywt\n",
    "import biosppy.signals.ecg as bsp_ecg\n",
    "import biosppy.signals.tools as bsp_tools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.io import loadmat\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.signal as signal\n",
    "\n",
    "\n",
    "from utils import print_signal_qrs, print_signal, calcul_f1, perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406091c4-11c7-4b7a-90fa-d147cd57af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_csv/mit_bih_Arrhythmia/207.csv') #207\n",
    "mini = 0\n",
    "maxi = 10000\n",
    "\n",
    "ecg_signal = np.array(df[\"MLII\"], dtype=np.float32)[mini:maxi]\n",
    "fs = 360\n",
    "QRS = df[\"labels\"].dropna().tolist()\n",
    "QRS = [int(R) for R in QRS if R <= maxi and R <= maxi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b4938f-cffb-4de1-9762-dfcd7980abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "class StackedAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(StackedAutoEncoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for h_dim in hidden_dims:\n",
    "            self.autoencoders.append(AutoEncoder(prev_dim, h_dim))\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dims[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for ae in self.autoencoders:\n",
    "            x, _ = ae(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_autoencoder(ae, data, epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in data:\n",
    "            inputs, _ = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = ae(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Fonction d'entraînement du classificateur final\n",
    "def train_classifier(model, data, epochs=50, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in data:\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e950eac4-0c1b-46a3-863c-4e5552e386c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 40\u001B[0m\n\u001B[1;32m     37\u001B[0m input_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(ecg_segments, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Utilisation du modèle créé précédemment\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m(input_data)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess_ecg(ecg_signal, sampling_rate):\n",
    "    # Filtrage passe-bas (cutoff = 50 Hz)\n",
    "    low_pass_cutoff = 50.0\n",
    "    b, a = signal.butter(4, low_pass_cutoff / (0.5 * sampling_rate), btype='low')\n",
    "    ecg_low = signal.filtfilt(b, a, ecg_signal)\n",
    "    \n",
    "    # Filtrage passe-haut (cutoff = 0.5 Hz)\n",
    "    high_pass_cutoff = 0.5\n",
    "    b, a = signal.butter(4, high_pass_cutoff / (0.5 * sampling_rate), btype='high')\n",
    "    ecg_band = signal.filtfilt(b, a, ecg_low)\n",
    "    \n",
    "    # Filtrage notch (notch_freq = 50 Hz)\n",
    "    notch_freq = 50.0\n",
    "    b, a = signal.iirnotch(notch_freq, Q=30, fs=sampling_rate)\n",
    "    ecg_filtered = signal.filtfilt(b, a, ecg_band)\n",
    "    \n",
    "    # Normalisation\n",
    "    ecg_normalized = (ecg_filtered - np.mean(ecg_filtered)) / np.std(ecg_filtered)\n",
    "    \n",
    "    return ecg_normalized\n",
    "\n",
    "def segment_ecg(ecg_signal, segment_length, overlap=0.5):\n",
    "    segments = []\n",
    "    step = int(segment_length * (1 - overlap))\n",
    "    for start in range(0, len(ecg_signal) - segment_length + 1, step):\n",
    "        segments.append(ecg_signal[start:start + segment_length])\n",
    "    return np.array(segments)\n",
    "\n",
    "# Pré-traitement du signal ECG\n",
    "ecg_preprocessed = preprocess_ecg(ecg_signal, fs)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ecg_signals_normalized = scaler.fit_transform(ecg_signals)\n",
    "\n",
    "segment_length = 300\n",
    "segments = [ecg_signals_normalized[i:i+segment_length] for i in range(0, len(ecg_signals_normalized), segment_length)]\n",
    "\n",
    "# Conversion en format adapté pour le modèle\n",
    "train_data = np.array(segments)\n",
    "\n",
    "\n",
    "input_dim = 300  # dimension d'entrée des signaux ECG, supposons 300 échantillons par signal\n",
    "hidden_dims = [75, 15]  # dimensions des couches cachées de l'auto-encodeur\n",
    "output_dim = 2  # nombre de classes pour la classification binaire (présence ou absence de QRS)\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = StackedAutoEncoder(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Pré-entraîner chaque auto-encodeur\n",
    "for ae in model.autoencoders:\n",
    "    train_autoencoder(ae, train_data, epochs=50)\n",
    "\n",
    "# Affiner l'ensemble du modèle\n",
    "train_classifier(model, train_data, epochs=50)\n",
    "\n",
    "\n",
    "\n",
    "# Transmettre les segments au modèle\n",
    "input_data = torch.tensor(ecg_segments, dtype=torch.float32)\n",
    "\n",
    "# Utilisation du modèle créé précédemment\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37213174-75ab-43be-a938-bed374b23b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a6450-f36a-4686-a452-5aaf0ef56b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bc463-b31c-451c-9f3d-623ea8684944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bc80e-bf4a-4f27-8055-b914c999e4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516045d5-874c-4303-af46-2e32de4d1376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b868b-a7ce-4544-beea-dc15a233cd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11814837",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_peaks = find_peaks(ecg_signal)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe696ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprint_signal_qrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mecg_signal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredicted\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr_peaks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/new/QRS_Detectors_SATO_Benchmark/utils.py:9\u001B[0m, in \u001B[0;36mprint_signal_qrs\u001B[0;34m(signal, qrs, true_qrs, mini, maxi, description)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maxi \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m      8\u001B[0m     maxi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(signal)\n\u001B[0;32m----> 9\u001B[0m cut_qrs \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmini\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mqrs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmaxi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmini\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     10\u001B[0m true_cut_qrs \u001B[38;5;241m=\u001B[39m [a \u001B[38;5;241m-\u001B[39m mini \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m true_qrs \u001B[38;5;28;01mif\u001B[39;00m a \u001B[38;5;241m<\u001B[39m maxi \u001B[38;5;129;01mand\u001B[39;00m a \u001B[38;5;241m>\u001B[39m mini]\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msignal de longueur: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(signal)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/new/QRS_Detectors_SATO_Benchmark/utils.py:9\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maxi \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m      8\u001B[0m     maxi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(signal)\n\u001B[0;32m----> 9\u001B[0m cut_qrs \u001B[38;5;241m=\u001B[39m [a \u001B[38;5;241m-\u001B[39m mini \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m qrs \u001B[38;5;28;01mif\u001B[39;00m \u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmaxi\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m a \u001B[38;5;241m>\u001B[39m mini]\n\u001B[1;32m     10\u001B[0m true_cut_qrs \u001B[38;5;241m=\u001B[39m [a \u001B[38;5;241m-\u001B[39m mini \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m true_qrs \u001B[38;5;28;01mif\u001B[39;00m a \u001B[38;5;241m<\u001B[39m maxi \u001B[38;5;129;01mand\u001B[39;00m a \u001B[38;5;241m>\u001B[39m mini]\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msignal de longueur: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(signal)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "print_signal_qrs(ecg_signal, \"predicted\", r_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a081e0b-7258-4872-8d17-5271eccf37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error = 0.5 * [(y[i] - t[i]) **2 for i in range(len(t))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c263f6-ca6e-4051-899f-2b3732eba1e8",
   "metadata": {},
   "source": [
    "L'algo :\n",
    "\n",
    "Détection peaks primaire : ?\n",
    "\n",
    "Selection des QRS: Stacked-auto-encoder pour choisir les QRS intéressant, fênetre de 54 autour du peak (26 avant, 27 après)\n",
    "\n",
    "Affinage de la selection : MLP avec 20 neurones +  les RR intervals pour estimer mieux les QRS\n",
    "\n",
    "QRS selection final : MLP avec 4 neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518df5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.142287015914917\n",
      "Epoch 20, Loss: 1.0653512477874756\n",
      "Epoch 30, Loss: 0.9900347590446472\n",
      "Epoch 40, Loss: 0.9174520373344421\n",
      "Epoch 50, Loss: 0.8495411276817322\n",
      "Epoch 60, Loss: 0.7932561039924622\n",
      "Epoch 70, Loss: 0.750663697719574\n",
      "Epoch 80, Loss: 0.7206009030342102\n",
      "Epoch 90, Loss: 0.6997930407524109\n",
      "Epoch 100, Loss: 0.68441241979599\n",
      "Epoch 10, Loss: 1.1716647148132324\n",
      "Epoch 20, Loss: 1.1046124696731567\n",
      "Epoch 30, Loss: 1.0511226654052734\n",
      "Epoch 40, Loss: 1.0040850639343262\n",
      "Epoch 50, Loss: 0.9563652873039246\n",
      "Epoch 60, Loss: 0.9098278284072876\n",
      "Epoch 70, Loss: 0.8677536845207214\n",
      "Epoch 80, Loss: 0.831939160823822\n",
      "Epoch 90, Loss: 0.8028867840766907\n",
      "Epoch 100, Loss: 0.7781325578689575\n",
      "Epoch 10, Loss: 1.1870919466018677\n",
      "Epoch 20, Loss: 1.1594970226287842\n",
      "Epoch 30, Loss: 1.1565465927124023\n",
      "Epoch 40, Loss: 1.156393051147461\n",
      "Epoch 50, Loss: 1.1563994884490967\n",
      "Epoch 60, Loss: 1.1563352346420288\n",
      "Epoch 70, Loss: 1.1563091278076172\n",
      "Epoch 80, Loss: 1.1563079357147217\n",
      "Epoch 90, Loss: 1.1563069820404053\n",
      "Epoch 100, Loss: 1.1563057899475098\n",
      "tensor([[0.2279],\n",
      "        [0.2325],\n",
      "        [0.1291],\n",
      "        [0.2560],\n",
      "        [0.2748],\n",
      "        [0.2679],\n",
      "        [0.2739],\n",
      "        [0.2461],\n",
      "        [0.3094],\n",
      "        [0.2205]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieu\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([10, 54])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "def scaled_conjugate_gradient(f, x0, args=(), **kwargs):\n",
    "    # ... Implémentation de l'algorithme ...\n",
    "    return x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(True)  # ou nn.Sigmoid() si les valeurs de sortie doivent être entre 0 et 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "sizes = [(54, 30, 54), (54, 20, 54), (54, 10, 1)]\n",
    "autoencoders = [Autoencoder(*size) for size in sizes]\n",
    "criterion = nn.MSELoss()\n",
    "optimizers = [optim.Adam(ae.parameters(), lr=0.001) for ae in autoencoders]\n",
    "\n",
    "x = torch.randn(10, 54)  # 10 exemples, chaque exemple de taille 54\n",
    "\n",
    "for ae, optimizer in zip(autoencoders, optimizers):\n",
    "    for epoch in range(100):  # Nombre d'époques de formation\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = ae(x)\n",
    "        loss = criterion(y_pred, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def stacked_autoencoders(autoencoders, x):\n",
    "    for ae in autoencoders:\n",
    "        x = ae(x)\n",
    "    return x\n",
    "\n",
    "y = stacked_autoencoders(autoencoders, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5470e7fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 46\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):  \u001B[38;5;66;03m# loop over the dataset multiple times\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 46\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(inputs)  \u001B[38;5;66;03m# forward pass\u001B[39;00m\n\u001B[0;32m     47\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, inputs)  \u001B[38;5;66;03m# calculate the loss\u001B[39;00m\n\u001B[0;32m     48\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# backward pass\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim3, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define the dimensions of the input, hidden and output layers\n",
    "input_dim = 54\n",
    "hidden_dim1 = 32\n",
    "hidden_dim2 = 16\n",
    "hidden_dim3 = 8\n",
    "output_dim = 1\n",
    "\n",
    "# Create the stacked autoencoder model\n",
    "model = AutoEncoder(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)  # forward pass\n",
    "    loss = criterion(outputs, inputs)  # calculate the loss\n",
    "    loss.backward()  # backward pass\n",
    "    optimizer.step()  # update the model parameters\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84f958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0273a5d2-3209-4838-8a71-70f40c88d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = \n",
    "\n",
    "def detect_peaks(signal, fs, minimum_interval=0.1):\n",
    "    \"\"\"Détecte les pics dans le signal ECG en utilisant find_peaks.\"\"\"\n",
    "    min_distance = int(fs * minimum_interval)\n",
    "    peaks, _ = find_peaks(signal, distance=min_distance)\n",
    "    return peaks\n",
    "\n",
    "def extract_windows(signal, peaks, window_size=54):\n",
    "    \"\"\"Extrait les fenêtres de 54 échantillons autour des pics détectés.\"\"\"\n",
    "    half_window = window_size // 2\n",
    "    windows = []\n",
    "    for peak in peaks:\n",
    "        start = max(0, peak - half_window)\n",
    "        end = min(len(signal), peak + half_window)\n",
    "        window = signal[start:end]\n",
    "        if len(window) < window_size:\n",
    "            padding = window_size - len(window)\n",
    "            if start == 0:\n",
    "                window = np.pad(window, (padding, 0), mode='constant')\n",
    "            else:\n",
    "                window = np.pad(window, (0, padding), mode='constant')\n",
    "        windows.append(window)\n",
    "    return np.array(windows)\n",
    "\n",
    "def normalize_windows(windows):\n",
    "    \"\"\"Normalise chaque fenêtre de 54 échantillons.\"\"\"\n",
    "    return (windows - np.mean(windows, axis=1, keepdims=True)) / np.std(windows, axis=1, keepdims=True)\n",
    "\n",
    "def label_windows(peaks, qrs_indices, fs, min_distance=0.1):\n",
    "    \"\"\"Crée des étiquettes pour chaque fenêtre (1 = QRS, 0 = non-QRS).\"\"\"\n",
    "    labels = np.zeros(len(peaks), dtype=int)\n",
    "    qrs_set = set(qrs_indices)\n",
    "    min_distance_samples = int(fs * min_distance)\n",
    "    for i, peak in enumerate(peaks):\n",
    "        if any(abs(peak - qrs) <= min_distance_samples for qrs in qrs_set):\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Autoencodeur simple avec une couche cachée.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(hidden_sizes):\n",
    "            layers.append(nn.Linear(input_size if i == 0 else hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class QRSDetector(nn.Module):\n",
    "    \"\"\"Combinaison de l'autoencodeur et des MLP pour la détection de QRS.\"\"\"\n",
    "    def __init__(self, input_size=54, ae_hidden_size=27, mlp1_hidden=20, mlp2_hidden=4):\n",
    "        super(QRSDetector, self).__init__()\n",
    "        self.autoencoder = Autoencoder(input_size, ae_hidden_size)\n",
    "        self.mlp1 = MLP(ae_hidden_size + 16, mlp1_hidden, 1)\n",
    "        self.mlp2 = MLP(ae_hidden_size + 16, mlp2_hidden, 1)\n",
    "\n",
    "    def forward(self, window, rr_intervals, amplitudes):\n",
    "        reconstructed, encoded = self.autoencoder(window)\n",
    "        features = torch.cat([encoded, rr_intervals, amplitudes], dim=1)\n",
    "        output1 = self.mlp1(features)\n",
    "        output2 = self.mlp2(features)\n",
    "        return output1, output2\n",
    "\n",
    "def autoencoder_loss(reconstructed, original):\n",
    "    \"\"\"Calcul de la perte MSE pour l'autoencodeur.\"\"\"\n",
    "    return F.mse_loss(reconstructed, original)\n",
    "\n",
    "def fine_tuning_loss(output, targets):\n",
    "    \"\"\"Fonction de perte d'entropie croisée pour le fine-tuning.\"\"\"\n",
    "    return F.cross_entropy(output, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87aa08df-17c4-4699-ad4f-84cf96e412ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(signal, qrs_indices, fs):\n",
    "    \"\"\"Prépare les données pour l'entraînement.\"\"\"\n",
    "    peaks = detect_peaks(signal, fs)\n",
    "    windows = extract_windows(signal, peaks)\n",
    "    windows = normalize_windows(windows)\n",
    "    labels = label_windows(peaks, qrs_indices, fs)\n",
    "\n",
    "    # Calcul des intervalles RR et des amplitudes des pics\n",
    "    rr_intervals = np.diff(peaks, prepend=0)\n",
    "    rr_intervals = np.concatenate([rr_intervals[-3:], rr_intervals])\n",
    "    amplitudes = signal[peaks]\n",
    "\n",
    "    # Préparation des caractéristiques pour chaque fenêtre\n",
    "    features = []\n",
    "    for i in range(len(peaks)):\n",
    "        rr_window = rr_intervals[max(0, i-3):i+5]\n",
    "        amp_window = amplitudes[max(0, i-3):i+5]\n",
    "        if len(rr_window) < 8:\n",
    "            rr_window = np.pad(rr_window, (8 - len(rr_window), 0), 'constant')\n",
    "        if len(amp_window) < 8:\n",
    "            amp_window = np.pad(amp_window, (8 - len(amp_window), 0), 'constant')\n",
    "        features.append(np.concatenate([rr_window, amp_window]))\n",
    "    features = np.array(features)\n",
    "\n",
    "    return torch.tensor(windows, dtype=torch.float32), torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "def train_qrs_detector(signal, qrs_indices, fs=360, epochs=100, batch_size=16):\n",
    "    \"\"\"Entraîne le détecteur de QRS sur les 20% premiers du dataset.\"\"\"\n",
    "    # Préparation des données\n",
    "    windows, features, labels = prepare_data(signal, qrs_indices, fs)\n",
    "\n",
    "    # Utilisation des 20% premiers pour l'entraînement\n",
    "    num_samples = int(len(windows) * 0.2)\n",
    "    X_train, X_val = windows[:num_samples], windows[num_samples:]\n",
    "    features_train, features_val = features[:num_samples], features[num_samples:]\n",
    "    y_train, y_val = labels[:num_samples], labels[num_samples:]\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, features_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, features_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialisation du modèle et des optimisateurs\n",
    "    model = QRSDetector()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Boucle d'entraînement\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for windows_batch, features_batch, labels_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(windows_batch, features_batch[:, :8], features_batch[:, 8:])\n",
    "            loss = custom_loss(output1, output2, labels_batch.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for windows_batch, features_batch, labels_batch in val_loader:\n",
    "                output1, output2 = model(windows_batch, features_batch[:, :8], features_batch[:, 8:])\n",
    "                loss = custom_loss(output1, output2, labels_batch.view(-1, 1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_qrs(signal, model, fs=360, threshold=0.5):\n",
    "    \"\"\"Prédit les complexes QRS dans le signal donné en utilisant le modèle entraîné.\"\"\"\n",
    "    peaks = detect_peaks(signal, fs)\n",
    "    windows = extract_windows(signal, peaks)\n",
    "    windows = normalize_windows(windows)\n",
    "\n",
    "    rr_intervals = np.diff(peaks, prepend=0)\n",
    "    rr_intervals = np.concatenate([rr_intervals[-3:], rr_intervals])\n",
    "    amplitudes = signal[peaks]\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(peaks)):\n",
    "        rr_window = rr_intervals[max(0, i-3):i+5]\n",
    "        amp_window = amplitudes[max(0, i-3):i+5]\n",
    "        if len(rr_window) < 8:\n",
    "            rr_window = np.pad(rr_window, (8 - len(rr_window), 0), 'constant')\n",
    "        if len(amp_window) < 8:\n",
    "            amp_window = np.pad(amp_window, (8 - len(amp_window), 0), 'constant')\n",
    "        features.append(np.concatenate([rr_window, amp_window]))\n",
    "    features = np.array(features)\n",
    "\n",
    "    windows_tensor = torch.tensor(windows, dtype=torch.float32)\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output1, output2 = model(windows_tensor, features_tensor[:, :8], features_tensor[:, 8:])\n",
    "        predictions = (output2.squeeze() >= threshold).numpy()\n",
    "\n",
    "    qrs_indices = peaks[predictions]\n",
    "    return qrs_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffc3f6a-5b75-4d83-a1ff-460eef779ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m fs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m360\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Entraîner le détecteur de QRS\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m train_qrs_detector(ecg_signal, qrs_indices, fs)\n\u001B[0;32m      6\u001B[0m predicted_qrs_indices \u001B[38;5;241m=\u001B[39m predict_qrs(ecg_signal, model, fs)\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n",
      "Cell \u001B[1;32mIn[10], line 45\u001B[0m, in \u001B[0;36mtrain_qrs_detector\u001B[1;34m(signal, qrs_indices, fs, epochs, batch_size)\u001B[0m\n\u001B[0;32m     42\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Initialisation du modèle et des optimisateurs\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m model \u001B[38;5;241m=\u001B[39m QRSDetector()\n\u001B[0;32m     46\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Boucle d'entraînement\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[9], line 76\u001B[0m, in \u001B[0;36mQRSDetector.__init__\u001B[1;34m(self, input_size, ae_hidden_size, mlp1_hidden, mlp2_hidden)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28msuper\u001B[39m(QRSDetector, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautoencoder \u001B[38;5;241m=\u001B[39m Autoencoder(input_size, ae_hidden_size)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp1 \u001B[38;5;241m=\u001B[39m MLP(ae_hidden_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m16\u001B[39m, mlp1_hidden, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp2 \u001B[38;5;241m=\u001B[39m MLP(ae_hidden_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m16\u001B[39m, mlp2_hidden, \u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[9], line 63\u001B[0m, in \u001B[0;36mMLP.__init__\u001B[1;34m(self, input_size, hidden_sizes, output_size)\u001B[0m\n\u001B[0;32m     61\u001B[0m layers \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(hidden_sizes):\n\u001B[1;32m---> 63\u001B[0m     layers\u001B[38;5;241m.\u001B[39mappend(nn\u001B[38;5;241m.\u001B[39mLinear(input_size \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m hidden_sizes[i\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], hidden_sizes[i]))\n\u001B[0;32m     64\u001B[0m     layers\u001B[38;5;241m.\u001B[39mappend(nn\u001B[38;5;241m.\u001B[39mReLU())\n\u001B[0;32m     65\u001B[0m layers\u001B[38;5;241m.\u001B[39mappend(nn\u001B[38;5;241m.\u001B[39mLinear(hidden_sizes[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], output_size))\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "qrs_indices = QRS\n",
    "fs = 360\n",
    "\n",
    "# Entraîner le détecteur de QRS\n",
    "model = train_qrs_detector(ecg_signal, qrs_indices, fs)\n",
    "predicted_qrs_indices = predict_qrs(ecg_signal, model, fs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ecg_signal, label='ECG Signal')\n",
    "plt.scatter(predicted_qrs_indices, ecg_signal[predicted_qrs_indices], color='red', label='Predicted QRS')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8befb68c-b0d0-4060-aea1-8d01f0dddc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 1615, 150)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(QRS, predicted_qrs_indices, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e38eda9-7026-42b5-a685-1eaf2d8e6540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 1615, 150)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(QRS, predicted_qrs_indices, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f0b5f-f6e3-455e-9fcc-cfcb4b965675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88764de3-396a-40ed-b6ce-74f76943fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf(labels, peaks, minmax):\n",
    "    x = np.concatenate([np.array(labels), np.array(peaks)]) #list(set(QRS + r_peaks))\n",
    "    x.sort()\n",
    "    diff = x[1:]-x[:-1]\n",
    "    gps = np.concatenate([[0], np.cumsum(diff>=minmax)])\n",
    "    temp = [x[gps==i] for i in range(gps[-1]+1)]\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    list_F = []\n",
    "    for sublist in temp:\n",
    "        if len(sublist) == 2:\n",
    "            TP += 1\n",
    "        else:\n",
    "            list_F.append(sublist)\n",
    "            if sublist[0] in labels:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    return TP, FP, FN #, list_F\n",
    "\n",
    "def print_signal(signal, description):\n",
    "    print(f\"signal de longueur: {len(signal)}\")\n",
    "    plt.figure()\n",
    "    plt.plot(signal)\n",
    "    #plt.scatter(QRS, [signal[i] for i in QRS], color='red')\n",
    "    plt.title(label= description)\n",
    "    plt.show()\n",
    "    \n",
    "def print_signal_qrs(signal, description, qrs):\n",
    "    print(f\"signal de longueur: {len(signal)}\")\n",
    "    plt.figure()\n",
    "    plt.plot(signal)\n",
    "    plt.scatter(qrs, [signal[i] for i in qrs], color='red')\n",
    "    plt.title(label= description)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
